<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Roman Tataurov" />

<meta name="date" content="2015-04-26" />

<title>Practical Machine Learning Course Project</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link href="data:text/css,body%20%7B%0A%20%20background%2Dcolor%3A%20%23fff%3B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20max%2Dwidth%3A%20700px%3B%0A%20%20overflow%3A%20visible%3B%0A%20%20padding%2Dleft%3A%202em%3B%0A%20%20padding%2Dright%3A%202em%3B%0A%20%20font%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0A%20%20font%2Dsize%3A%2014px%3B%0A%20%20line%2Dheight%3A%201%2E35%3B%0A%7D%0A%0A%23header%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0A%0A%23TOC%20%7B%0A%20%20clear%3A%20both%3B%0A%20%20margin%3A%200%200%2010px%2010px%3B%0A%20%20padding%3A%204px%3B%0A%20%20width%3A%20400px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20border%2Dradius%3A%205px%3B%0A%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20font%2Dsize%3A%2013px%3B%0A%20%20line%2Dheight%3A%201%2E3%3B%0A%7D%0A%20%20%23TOC%20%2Etoctitle%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%20%20font%2Dsize%3A%2015px%3B%0A%20%20%20%20margin%2Dleft%3A%205px%3B%0A%20%20%7D%0A%0A%20%20%23TOC%20ul%20%7B%0A%20%20%20%20padding%2Dleft%3A%2040px%3B%0A%20%20%20%20margin%2Dleft%3A%20%2D1%2E5em%3B%0A%20%20%20%20margin%2Dtop%3A%205px%3B%0A%20%20%20%20margin%2Dbottom%3A%205px%3B%0A%20%20%7D%0A%20%20%23TOC%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dleft%3A%20%2D2em%3B%0A%20%20%7D%0A%20%20%23TOC%20li%20%7B%0A%20%20%20%20line%2Dheight%3A%2016px%3B%0A%20%20%7D%0A%0Atable%20%7B%0A%20%20margin%3A%201em%20auto%3B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dcolor%3A%20%23DDDDDD%3B%0A%20%20border%2Dstyle%3A%20outset%3B%0A%20%20border%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0A%20%20border%2Dwidth%3A%202px%3B%0A%20%20padding%3A%205px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0A%20%20border%2Dwidth%3A%201px%3B%0A%20%20border%2Dstyle%3A%20inset%3B%0A%20%20line%2Dheight%3A%2018px%3B%0A%20%20padding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0A%20%20border%2Dleft%2Dstyle%3A%20none%3B%0A%20%20border%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Ap%20%7B%0A%20%20margin%3A%200%2E5em%200%3B%0A%7D%0A%0Ablockquote%20%7B%0A%20%20background%2Dcolor%3A%20%23f6f6f6%3B%0A%20%20padding%3A%200%2E25em%200%2E75em%3B%0A%7D%0A%0Ahr%20%7B%0A%20%20border%2Dstyle%3A%20solid%3B%0A%20%20border%3A%20none%3B%0A%20%20border%2Dtop%3A%201px%20solid%20%23777%3B%0A%20%20margin%3A%2028px%200%3B%0A%7D%0A%0Adl%20%7B%0A%20%20margin%2Dleft%3A%200%3B%0A%7D%0A%20%20dl%20dd%20%7B%0A%20%20%20%20margin%2Dbottom%3A%2013px%3B%0A%20%20%20%20margin%2Dleft%3A%2013px%3B%0A%20%20%7D%0A%20%20dl%20dt%20%7B%0A%20%20%20%20font%2Dweight%3A%20bold%3B%0A%20%20%7D%0A%0Aul%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%7D%0A%20%20ul%20li%20%7B%0A%20%20%20%20list%2Dstyle%3A%20circle%20outside%3B%0A%20%20%7D%0A%20%20ul%20ul%20%7B%0A%20%20%20%20margin%2Dbottom%3A%200%3B%0A%20%20%7D%0A%0Apre%2C%20code%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20color%3A%20%23333%3B%0A%7D%0Apre%20%7B%0A%20%20white%2Dspace%3A%20pre%2Dwrap%3B%20%20%20%20%2F%2A%20Wrap%20long%20lines%20%2A%2F%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20margin%3A%205px%200px%2010px%200px%3B%0A%20%20padding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0A%20%20background%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0A%0Acode%20%7B%0A%20%20font%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0A%20%20font%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0A%20%20padding%3A%202px%200px%3B%0A%7D%0A%0Adiv%2Efigure%20%7B%0A%20%20text%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0A%20%20background%2Dcolor%3A%20%23FFFFFF%3B%0A%20%20padding%3A%202px%3B%0A%20%20border%3A%201px%20solid%20%23DDDDDD%3B%0A%20%20border%2Dradius%3A%203px%3B%0A%20%20border%3A%201px%20solid%20%23CCCCCC%3B%0A%20%20margin%3A%200%205px%3B%0A%7D%0A%0Ah1%20%7B%0A%20%20margin%2Dtop%3A%200%3B%0A%20%20font%2Dsize%3A%2035px%3B%0A%20%20line%2Dheight%3A%2040px%3B%0A%7D%0A%0Ah2%20%7B%0A%20%20border%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20padding%2Dbottom%3A%202px%3B%0A%20%20font%2Dsize%3A%20145%25%3B%0A%7D%0A%0Ah3%20%7B%0A%20%20border%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0A%20%20padding%2Dtop%3A%2010px%3B%0A%20%20font%2Dsize%3A%20120%25%3B%0A%7D%0A%0Ah4%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0A%20%20margin%2Dleft%3A%208px%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Ah5%2C%20h6%20%7B%0A%20%20border%2Dbottom%3A%201px%20solid%20%23ccc%3B%0A%20%20font%2Dsize%3A%20105%25%3B%0A%7D%0A%0Aa%20%7B%0A%20%20color%3A%20%230033dd%3B%0A%20%20text%2Ddecoration%3A%20none%3B%0A%7D%0A%20%20a%3Ahover%20%7B%0A%20%20%20%20color%3A%20%236666ff%3B%20%7D%0A%20%20a%3Avisited%20%7B%0A%20%20%20%20color%3A%20%23800080%3B%20%7D%0A%20%20a%3Avisited%3Ahover%20%7B%0A%20%20%20%20color%3A%20%23BB00BB%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%20%20a%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0A%20%20%20%20text%2Ddecoration%3A%20underline%3B%20%7D%0A%0A%2F%2A%20Class%20described%20in%20https%3A%2F%2Fbenjeffrey%2Ecom%2Fposts%2Fpandoc%2Dsyntax%2Dhighlighting%2Dcss%0A%20%20%20Colours%20from%20https%3A%2F%2Fgist%2Egithub%2Ecom%2Frobsimmons%2F1172277%20%2A%2F%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Keyword%20%2A%2F%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%2F%2A%20DataType%20%2A%2F%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%2F%2A%20DecVal%20%28decimal%20values%29%20%2A%2F%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20BaseN%20%2A%2F%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Float%20%2A%2F%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20Char%20%2A%2F%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%2F%2A%20String%20%2A%2F%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%2F%2A%20Comment%20%2A%2F%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%2F%2A%20OtherToken%20%2A%2F%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20AlertToken%20%2A%2F%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%2F%2A%20Function%20calls%20%2A%2F%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%2F%2A%20ErrorTok%20%2A%2F%0A%0A" rel="stylesheet" type="text/css" />

</head>

<body>



<div id="header">
<h1 class="title">Practical Machine Learning Course Project</h1>
<h4 class="author"><em>Roman Tataurov</em></h4>
<h4 class="date"><em>2015-04-26</em></h4>
</div>


<div id="background" class="section level1">
<h1>Background</h1>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly.</p>
<p>In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.</p>
</div>
<div id="question" class="section level1">
<h1>Question</h1>
<p>The goal of your project is to predict the manner in which they did the exercise. This is the “classe” variable in the training set. Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.</p>
</div>
<div id="working-environment" class="section level1">
<h1>Working environment</h1>
<p>Lets load some libraries required and set a pseudo random seed.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(knitr)
opts_chunk$<span class="kw">set</span>(<span class="dt">echo =</span> <span class="ot">TRUE</span>, <span class="dt">results =</span> <span class="st">'hold'</span>)
<span class="kw">library</span>(lattice)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(caret)
<span class="kw">library</span>(rpart)
<span class="kw">library</span>(rpart.plot)
<span class="kw">library</span>(rattle)</code></pre>
<pre><code>## Rattle: A free graphical interface for data mining with R.
## Version 3.4.1 Copyright (c) 2006-2014 Togaware Pty Ltd.
## Type 'rattle()' to shake, rattle, and roll your data.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(randomForest)</code></pre>
<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(missForest)</code></pre>
<pre><code>## Loading required package: foreach
## Loading required package: itertools
## Loading required package: iterators</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gbm)</code></pre>
<pre><code>## Loading required package: survival
## 
## Attaching package: 'survival'
## 
## The following object is masked from 'package:caret':
## 
##     cluster
## 
## Loading required package: splines
## Loading required package: parallel
## Loaded gbm 2.1.1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(knitr)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)</code></pre>
</div>
<div id="input-data" class="section level1">
<h1>Input data</h1>
<p>Lets prepare common function to download an remember our source data. While import files also cleaning data from some misformatted values which obvioulsy mean absense of value (<code>NA</code>, <code>#DIV/0!</code> and just an empty cells).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dir.create</span>(<span class="st">&quot;./data&quot;</span>, <span class="dt">showWarnings =</span> <span class="ot">FALSE</span>, <span class="dt">recursive =</span> <span class="ot">TRUE</span>, <span class="dt">mode =</span> <span class="st">&quot;0777&quot;</span>)

loadData &lt;-<span class="st"> </span>function(type) {
  filename=<span class="kw">paste</span>(<span class="st">&quot;./data/&quot;</span>, <span class="st">&quot;pml-&quot;</span>, type, <span class="st">&quot;.csv&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)
  if (!<span class="kw">file.exists</span>(filename)) {
    url &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;http://d396qusza40orc.cloudfront.net/predmachlearn/pml-&quot;</span>, type ,<span class="st">&quot;.csv&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)
    <span class="kw">message</span>(<span class="kw">paste</span>(<span class="st">&quot;Please Wait! Downloading...&quot;</span>, url, <span class="st">&quot;...&quot;</span>))
    <span class="kw">download.file</span>(url, <span class="dt">destfile=</span>filename)
  } 
  data =<span class="st"> </span><span class="kw">read.csv</span>(filename, <span class="dt">header=</span><span class="ot">TRUE</span>, <span class="dt">sep=</span><span class="st">&quot;,&quot;</span>, <span class="dt">na.strings=</span><span class="kw">c</span>(<span class="st">&quot;NA&quot;</span>,<span class="st">&quot;#DIV/0!&quot;</span>,<span class="st">&quot;&quot;</span>))
  <span class="kw">return</span>(data)
}</code></pre>
<p>Well - now lets load our data and prepare <code>pmlTraining</code> and <code>pmlTesting</code> datasets</p>
<pre class="sourceCode r"><code class="sourceCode r">pmlTraining &lt;-<span class="st"> </span><span class="kw">loadData</span>(<span class="st">&quot;training&quot;</span>)
pmlTesting  &lt;-<span class="st"> </span><span class="kw">loadData</span>(<span class="st">&quot;testing&quot;</span>)</code></pre>
<p>Lets briefly review our <code>pmlTraining</code> dataset</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(pmlTraining) </code></pre>
<pre><code>## [1] 19622   160</code></pre>
<p>So we have 160 columns so it mean 159 predictors - pretty big value. So its a good reason to think about some data cleaning.</p>
</div>
<div id="prepare-test-data" class="section level1">
<h1>Prepare test data</h1>
<div id="split-our-source-training-dataset" class="section level2">
<h2>Split our source training dataset</h2>
<p>Well now time to move close to research so lets split our <code>training</code> dataset using common 60%/40% rule.</p>
<pre class="sourceCode r"><code class="sourceCode r">inTrain &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y=</span>pmlTraining$classe, <span class="dt">p=</span><span class="fl">0.6</span>, <span class="dt">list=</span><span class="ot">FALSE</span>)
training &lt;-<span class="st"> </span>pmlTraining[inTrain, ]
testing  &lt;-<span class="st"> </span>pmlTraining[-inTrain, ]
<span class="kw">dim</span>(training); 
<span class="kw">dim</span>(testing)</code></pre>
<pre><code>## [1] 11776   160
## [1] 7846  160</code></pre>
</div>
<div id="cleanup-training-data" class="section level2">
<h2>Cleanup training data</h2>
<div id="remove-columns-with-lot-of-na" class="section level3">
<h3>Remove columns with lot of NA</h3>
<p>Lets remove variables with more than 80% of NA values.</p>
<pre class="sourceCode r"><code class="sourceCode r">filledColumns =<span class="st"> </span><span class="kw">c</span>((<span class="kw">colSums</span>(!<span class="kw">is.na</span>(training[,-<span class="kw">ncol</span>(training)])) &gt;=<span class="st"> </span><span class="fl">0.8</span>*<span class="kw">nrow</span>(training)))
training &lt;-<span class="st"> </span>training[, filledColumns]
testing  &lt;-<span class="st"> </span>testing[, filledColumns]
<span class="kw">dim</span>(training)
<span class="kw">dim</span>(testing)</code></pre>
<pre><code>## [1] 11776    60
## [1] 7846   60</code></pre>
<p>So as result we got 60 variables instead of 160</p>
</div>
<div id="remove-near-zero-values" class="section level3">
<h3>Remove near zero values</h3>
<p>Lets find covariance with variability close to zero and remove it.</p>
<pre class="sourceCode r"><code class="sourceCode r">nzv &lt;-<span class="st"> </span><span class="kw">nearZeroVar</span>(training, <span class="dt">saveMetrics=</span><span class="ot">TRUE</span>)
training =<span class="st"> </span><span class="kw">subset</span>(training, <span class="dt">select=</span><span class="kw">rownames</span>(nzv[<span class="kw">which</span>(nzv$nzv==<span class="ot">FALSE</span> &amp;<span class="st"> </span>nzv$zeroVar==<span class="ot">FALSE</span>),]))
<span class="kw">dim</span>(training)</code></pre>
<pre><code>## [1] 11776    59</code></pre>
<p>Not a big advantage because now we have 59 variables instead of 60</p>
</div>
<div id="remove-some-known-variable" class="section level3">
<h3>Remove some known variable</h3>
<p>Lets remove timestamp variables as well as user names and identifiers.</p>
<pre class="sourceCode r"><code class="sourceCode r">training =<span class="st"> </span><span class="kw">subset</span>(training, <span class="dt">select=</span><span class="kw">c</span>(-X -raw_timestamp_part_1, -raw_timestamp_part_2, -cvtd_timestamp))
training =<span class="st"> </span><span class="kw">subset</span>(training, <span class="dt">select=</span><span class="kw">c</span>(-user_name))
training =<span class="st"> </span><span class="kw">subset</span>(training, <span class="dt">select=</span><span class="kw">c</span>(-raw_timestamp_part_1))
training =<span class="st"> </span><span class="kw">subset</span>(training, <span class="dt">select=</span><span class="kw">c</span>(-X))
<span class="kw">dim</span>(training)</code></pre>
<pre><code>## [1] 11776    54</code></pre>
<p>So finally we have only 56 predictors Now we can assume our training dataset clear and ready for later analysis</p>
</div>
</div>
</div>
<div id="building-models" class="section level1">
<h1>Building models</h1>
<div id="decision-tree" class="section level2">
<h2>Decision Tree</h2>
<pre class="sourceCode r"><code class="sourceCode r">training_DT &lt;-<span class="st"> </span>training
modFit_DT &lt;-<span class="st"> </span><span class="kw">rpart</span>(classe~., <span class="dt">data=</span>training_DT, <span class="dt">method=</span><span class="st">&quot;class&quot;</span>)
prediction_DT &lt;-<span class="st"> </span><span class="kw">predict</span>(modFit_DT, testing, <span class="dt">type=</span><span class="st">&quot;class&quot;</span>)
cm_DT &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(prediction_DT, testing$classe)
cm_DT</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1973  239   57   83   75
##          B   93  844   53   92  148
##          C   20  174 1086  206  111
##          D  120  166   93  841  172
##          E   26   95   79   64  936
## 
## Overall Statistics
##                                           
##                Accuracy : 0.7239          
##                  95% CI : (0.7139, 0.7338)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.6501          
##  Mcnemar's Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8840   0.5560   0.7939   0.6540   0.6491
## Specificity            0.9191   0.9390   0.9211   0.9160   0.9588
## Pos Pred Value         0.8129   0.6862   0.6800   0.6042   0.7800
## Neg Pred Value         0.9522   0.8981   0.9549   0.9311   0.9239
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2515   0.1076   0.1384   0.1072   0.1193
## Detection Prevalence   0.3093   0.1568   0.2035   0.1774   0.1529
## Balanced Accuracy      0.9015   0.7475   0.8575   0.7850   0.8039</code></pre>
</div>
<div id="random-forests" class="section level2">
<h2>Random Forests</h2>
<p>Lets try Random Forests apprach without some preprocessing</p>
<pre class="sourceCode r"><code class="sourceCode r">modFit_RF1 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(classe~., <span class="dt">data=</span>training)
prediction_RF1 &lt;-<span class="st"> </span><span class="kw">predict</span>(modFit_RF1, testing)
cm_RF1 &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(prediction_RF1, testing$classe)
cm_RF1</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2232    3    0    0    0
##          B    0 1512    6    0    0
##          C    0    3 1361   11    0
##          D    0    0    1 1274    2
##          E    0    0    0    1 1440
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9966         
##                  95% CI : (0.995, 0.9977)
##     No Information Rate : 0.2845         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9956         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9960   0.9949   0.9907   0.9986
## Specificity            0.9995   0.9991   0.9978   0.9995   0.9998
## Pos Pred Value         0.9987   0.9960   0.9898   0.9977   0.9993
## Neg Pred Value         1.0000   0.9991   0.9989   0.9982   0.9997
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2845   0.1927   0.1735   0.1624   0.1835
## Detection Prevalence   0.2849   0.1935   0.1752   0.1628   0.1837
## Balanced Accuracy      0.9997   0.9975   0.9964   0.9951   0.9992</code></pre>
<p>Previusly we already removed columns with more than 80% of NA values. Lets impute missing values with <code>missForest</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r">training_RF &lt;-<span class="st"> </span><span class="kw">missForest</span>(training, <span class="dt">ntree=</span><span class="dv">100</span>)
modFit_RF2 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(classe~., <span class="dt">data=</span>training_RF$ximp)
prediction_RF2 &lt;-<span class="st"> </span><span class="kw">predict</span>(modFit_RF2, testing)
cm_RF2 &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(prediction_RF2, testing$classe)
cm_RF2</code></pre>
<pre><code>##   missForest iteration 1 in progress...done!
##   missForest iteration 2 in progress...done!
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2232    5    0    0    0
##          B    0 1510    6    0    0
##          C    0    3 1361   11    0
##          D    0    0    1 1274    2
##          E    0    0    0    1 1440
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9963          
##                  95% CI : (0.9947, 0.9975)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9953          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9947   0.9949   0.9907   0.9986
## Specificity            0.9991   0.9991   0.9978   0.9995   0.9998
## Pos Pred Value         0.9978   0.9960   0.9898   0.9977   0.9993
## Neg Pred Value         1.0000   0.9987   0.9989   0.9982   0.9997
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2845   0.1925   0.1735   0.1624   0.1835
## Detection Prevalence   0.2851   0.1932   0.1752   0.1628   0.1837
## Balanced Accuracy      0.9996   0.9969   0.9964   0.9951   0.9992</code></pre>
<p>Imputing results are comparable but finally worse a little 0.9963 vs 09967 accuracy corrspondingly for imputet and raw data.</p>
</div>
</div>
<div id="conclusions" class="section level1">
<h1>Conclusions</h1>
<p>So we can see what Decision Tree algorithm has worse accuracy than Random Forests - 0.7239 vs 0.9967 correspondingly. So our final decision is Random Forests algorithm without impute.</p>
<table>
<thead>
<tr class="header">
<th align="left">Model</th>
<th align="right">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Desision Tree</td>
<td align="right">0.724</td>
</tr>
<tr class="even">
<td align="left">Random Forest</td>
<td align="right">0.997</td>
</tr>
<tr class="odd">
<td align="left">Random Forest with impute</td>
<td align="right">0.996</td>
</tr>
</tbody>
</table>
</div>
<div id="generate-files-for-submittion" class="section level1">
<h1>Generate files for submittion</h1>
<pre class="sourceCode r"><code class="sourceCode r">prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(modFit_RF1, pmlTesting, <span class="dt">type=</span><span class="st">&quot;class&quot;</span>)
<span class="kw">as.vector</span>(prediction)

<span class="kw">dir.create</span>(<span class="st">&quot;./submissions&quot;</span>, <span class="dt">showWarnings =</span> <span class="ot">FALSE</span>, <span class="dt">recursive =</span> <span class="ot">TRUE</span>, <span class="dt">mode =</span> <span class="st">&quot;0777&quot;</span>)
n &lt;-<span class="st"> </span><span class="kw">length</span>(prediction)
for(i in <span class="dv">1</span>:n){
  filename &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;./submissions/problem_id_&quot;</span>,i,<span class="st">&quot;.txt&quot;</span>)
  <span class="kw">write.table</span>(prediction[i],<span class="dt">file=</span>filename,<span class="dt">quote=</span><span class="ot">FALSE</span>,<span class="dt">row.names=</span><span class="ot">FALSE</span>,<span class="dt">col.names=</span><span class="ot">FALSE</span>)
}</code></pre>
<pre><code>##  [1] &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;E&quot; &quot;D&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot; &quot;E&quot; &quot;E&quot; &quot;A&quot;
## [18] &quot;B&quot; &quot;B&quot; &quot;B&quot;</code></pre>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
